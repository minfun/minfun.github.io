---
layout: post
title:  "Streaming with Apache Training"
date:   2019-02-21 11:20:13 +0800
categories: apache flink
---

## Apache Flink流式传输

本次培训主要专注在四个重要的概念：连续处理流数据，事件时间，有状态的流处理和状态快照。

## 流处理

流是数据天然的栖息地，无论是来自Web服务器的事件，来自证券交易所的交易，还是来自工厂车间的机器传感器读数，数据都是作为流的一部分创建的。但是当我们分析数据时，我们可以围绕有界或无界流组织我们的处理过程，我们选择的范式会产生生远的影响。

![bounded-unbounded](/assets/image/apache/flink/training/bounded-unbounded.png)

**批处理** 是我们处理有界数据流时的工作范例。这种操作模式中我们可以选择在产生任何结果之前注入整个数据集，例如，对数据进行排序，计算全局统计信息或生成汇总所有输入的最终报告。

**流处理** 另一方面，流处理涉及无界数据流。从概念上来说，至少输入可能永远不会结束，因此我们被迫在数据抵达时进行连续处理。

在Flink中，应用程序由用户定义的算子转换的数据流组成。这些数据流形成有向图，这些图以一个或多个源开头，并以一个或多个接收器结束。

![source-transform-sink-update](/assets/image/apache/flink/training/source-transform-sink-update.png)

一个应用可能从流式源消费实时数据如消息队列或分布式日志，例如Apache Kafka或Kinesis。但是Flink也可以从很多数据源中获取有界的，历史的数据。类似的，Flink应用程序生成的结果流可以发送到各种系统，Flink中保存的状态可以通过REST API访问。

![flink-application-sources-sinks](/assets/image/apache/flink/training/flink-application-sources-sinks.png)

## 实时流处理

对于大多数流式应用而言，使用处理实时数据的相同代码重新处理历史数据并生成确定的，一致的结果是非常有价值的

同样关键的是注意时间触发的顺序，而不是事件被处理的顺序，以及能够推断一组事件何时完成。例如考虑电子商务交易或者金融交易中涉及的一系列事件。

这些对于实时流处理要求使用记录在数据流中的事件时间的时间戳，而不是使用处理数据的机器时间。

## 状态流处理

Flink的操作是有状态的。这意味着一个事件如何被处理取决于在此之前的事件所积累的影响。状态可能被用于一些简单的事情，例如计算每分钟显示在面板上的事件，或者用于一些复杂的事情，例如用于欺诈检测模型计算特征。

Flink应用程序在分布式集群上并行运行。给定运算符的各种并行实例将在单独的线程中独立执行，并且通常将在不同的机器上运行。

有状态运算符的并行实例集实际上是分片键值存储。每个并行实例负责处理特定键组的事件，并且这些键的状态保存在本地。

下图显示了作业图中前三个运算符的并行度为2的作业，终止于并行度为1的接收器。第三个运算符是有状态的，我们看到第二个和第三个运算符之间正在发生完全连接的网络洗牌。这样做是为了通过某个键对流进行分区，以便一起处理所有需要处理的事件。

![parallel-job](/assets/image/apache/flink/training/parallel-job.png)

状态始终在本地访问，这有助于Flink应用程序实现高吞吐量和低延迟。您可以选择在JVM堆上保持状态，或者它太大了，有效的组织在磁盘数据结构上。

![local-state](/assets/image/apache/flink/training/local-state.png)

## 强大的流处理

Flink能够通过状态快照和流重放的组合提供容错和精确一次语义。这些快照捕捉分布式管道的全部状态，将偏移记录到输入队列中，以及整个作业图中的状态，这是因为已经将数据摄取到该点。当发生故障时，源被倒带，状态恢复，并且恢复处理。如上所述，这些状态快照是异步捕获的，而不会妨碍正在进行的处理。
